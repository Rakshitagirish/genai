import numpy as np
def softmax(x,axis=-1):
  exp_x=np.exp(x-np.max(x,axis=axis,keepdims=True))
  return exp_x/np.sum(exp_x,axis=axis,keepdims=True)
def self_att(x,wq,wk,wv):
  q=np.dot(x,wq)
  k=np.dot(x,wk)
  v=np.dot(x,wv)
  dk=q.shape[1]
  score=np.dot(q,k.T)/np.sqrt(dk)
  weights=softmax(score,axis=-1)
  output=np.dot(weights,v)
  return output
np.random.seed(0)
x=np.random.rand(4,3)
d=3
dout=2
wq=np.random.rand(d,dout)
wk=np.random.rand(d,dout)
wv=np.random.rand(d,dout)
y=self_att(x,wq,wk,wv)
print(x)
print(wq)
print(wk)
print(wv)
